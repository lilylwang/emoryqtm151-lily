{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import numpy as np # numPy - mathematical operations\n",
    "import matplotlib.pyplot as plt # matplotlib - generate graphs\n",
    "import pandas as pd # pandas - manipulate datasets\n",
    "import statsmodels.api as sm # function to estimate models\n",
    "import statsmodels.formula.api as smf # general use statistical options\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Built-in Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String printed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important functions to remember:\n",
    "\n",
    "print(\"String\")\n",
    "type(3.14) # returns int, str, boolean, float\n",
    "round(np.pi, 6) # rounds float to 5 decimal places\n",
    "abs(-4) # returns -4\n",
    "len(\"happy\") # returns length of strings or number elements in list (ex. 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 8: User-defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function\n",
    "def fn_status (numeric_grade):\n",
    "    if(numeric_grade >= 55):\n",
    "        status = \"pass\"\n",
    "    else:\n",
    "        status = \"fail\"\n",
    "    return status\n",
    "\n",
    "\n",
    "print(fn_status(56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda function\n",
    "fn_sum = lambda x,y,z: x + y + z\n",
    "fn_iseligible_vote = lambda age: (age>=18)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 9: Local/Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables defined are stored in working environment (can be referenced in other parts of notebook) ex. hi = \"hello\"\n",
    "# Although global var can be referenced inside functions, better to include inputs as parameters\n",
    "\n",
    "# Local variables are stored temporarily, supercede global variables  ex. defined inside functions\n",
    "# to permanently modify a variable, use \"global\"\n",
    "def modify_x():\n",
    "    global x\n",
    "    x = x + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = pd.DataFrame(  [ ] ) # empty data frame\n",
    "\n",
    "data[\"age\"] = [18,29,15,32,6] # data variables\n",
    "data[\"num_underage_siblings\"] = [0,0,1,1,0]\n",
    "data[\"num_adult_siblings\"]    = [1,0,0,1,0]\n",
    "\n",
    "fn_iseligible_vote = lambda age: age >= 18 # define function\n",
    "fn_istwenties      = lambda age: (age >= 20) & (age < 30)\n",
    "fn_sum             = lambda x,y: x + y\n",
    "\n",
    "# Apply function to dataframe series\n",
    "data[\"can_vote\"] = data[\"age\"].apply(fn_iseligible_vote) # apply function --> extract each eleement and return function value \n",
    "\n",
    "# Mapping functions with one or more arguments\n",
    "data[\"num_siblings\"] = list(map(fn_sum,\n",
    "                                    data[\"num_underage_siblings\"],\n",
    "                                    data[\"num_adult_siblings\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 10: Subsetting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the car features dataset\n",
    "carfeatures = pd.read_csv(\"data_raw/features.csv\")\n",
    "\n",
    "# The display() command will show the first 5 rows and the last five rows\n",
    "display(carfeatures)\n",
    "\n",
    "# Extract column names\n",
    "car_colnames = carfeatures.columns.values\n",
    "\n",
    "# Subset columns\n",
    "display(carfeatures[[\"weight\",\"mpg\"]])\n",
    "\n",
    "# Subset rows: data.iloc[lower:upper, : ]\n",
    "display(carsorted.iloc[0,:]) \n",
    "display(carfeatures.iloc[0:5,:]) # Extract rows 0 to 5\n",
    "display(car_ascendingmpg.iloc[:, 2]) # Extract column 2\n",
    "\n",
    "# Sort\n",
    "carsorted = carfeatures.sort_values(by = \"mpg\", ascending = False)\n",
    "\n",
    "# Query\n",
    "data_rangeweight    = carfeatures.query(\"(acceleration >= 10) & (acceleration < 18)\")\n",
    "threshold = 25\n",
    "data_varthreshold_mpg = carfeatures.query(\"mpg >= @threshold\") # need @ for column names\n",
    "data_spacesthreshold_mpg = carfeatures.query(\"`new variable` >= 25\") # need for spaces in column name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 11: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame([])\n",
    "\n",
    "# 2 random variable\n",
    "n = 50\n",
    "dataset[\"x\"] = np.random.normal(loc = 0,scale = 1, size = n)\n",
    "dataset[\"e\"] = np.random.normal(loc = 0,scale = 1, size = n) # error term\n",
    "\n",
    "# create data from linear model\n",
    "b0 = 1 # intercept\n",
    "b1 = 2 # slope\n",
    "dataset[\"y\"] = b0 + b1 * dataset[\"x\"] + dataset[\"e\"] # compute formulas\n",
    "\n",
    "# theoretical best fit line\n",
    "dataset[\"p\"] = b0 + b1*dataset[\"x\"]\n",
    "\n",
    "# summary statistics\n",
    "ybar = dataset[\"y\"].mean()\n",
    "stdv_sample = dataset[\"y\"].std()\n",
    "y_median = dataset[\"y\"].median()\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "# We use the subfunction \"ols()\" in the library \"smf\"\n",
    "#---- (i) The first argument is a string called \"formula\" with the format \n",
    "#-------- \"outcome ~ indepdent_vars\"\n",
    "#----(ii) the second argument is the dataset\n",
    "# The second line fits the model with standard errors \"cov\". In this case we \n",
    "# use \"robust\" standard errors (HC1)\n",
    "#-------------------------------------------------------------------------------#\n",
    "\n",
    "model   = smf.ols(formula = 'y ~  x',data = dataset)\n",
    "results = model.fit(cov = \"HC1\")\n",
    "\n",
    "# Can also run as one line\n",
    "# results = smf.ols(formula = 'y ~ x',data = dataset).fit(cov = \"HC1\")\n",
    "\n",
    "# We will use \".params\" to get the attribute \"parameters from the results\"\n",
    "\n",
    "b_list = results.params\n",
    "print(b_list)\n",
    "\n",
    "# We can then compute the \"estimated\" best fit lines\n",
    "# by extracting the intercept and slop from \"b_list\"\n",
    "\n",
    "dataset[\"p_estimated\"] = b_list[0] + b_list[1]  * dataset[\"x\"]\n",
    "\n",
    "# Note: The estimators for \"b0\" and \"b1\" are close to \n",
    "# the values we used to generate the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "(d) Split a dataset into subsets\n",
    "\n",
    "- You will be asked to randomly assign a status to each row\n",
    "- Split the data into separate datasets using \".query()\"\n",
    "- This will closely follow the material in Lecture 12 (this one)\n",
    "- You will need this result to answer questions (e), (f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your own code here -- subset by querying\n",
    "subset_above2 = dataset.query(\"y >= 2\")\n",
    "original = len(dataset)\n",
    "new = len(subset_above2)\n",
    "print(original)\n",
    "print(new)\n",
    "print(\"Proportion: \" + str(new/original))\n",
    "\n",
    "\n",
    "# Write your own code\n",
    "\n",
    "dataset[\"sample_error\"] = dataset[\"y\"] - dataset[\"p_estimated\"]\n",
    "\n",
    "# assigns pos error status to each row\n",
    "fn_pos_error= lambda error: error >= 0 \n",
    "\n",
    "dataset[\"pos_error\"] = list(map(fn_pos_error, dataset[\"sample_error\"]))\n",
    "dataset[\"positive_error\"] = dataset[\"sample_error\"].apply(fn_pos_error)\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "(e) Create a function with four inputs $f(y,x,b0,b1)$\n",
    "\n",
    "- Start by using \"def\" to define the function\n",
    "- The function will include arithmetic operations (Lecture 3) <br>\n",
    "and summary statistics for pandas (mean, std, min, max, etc.)\n",
    "- You will be asked to test different values of $(y,x,b0,b1)$\n",
    "- You will get $y$ and $x$ from the two datasets in part (d)\n",
    "- Note: You will **not** be required to use the \"statsmodels\" library\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics\n",
    "dataset[\"y\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"(f) Create two overlapping histogram plots\n",
    "\n",
    "- You will use a variable from the two datasets in (d)\n",
    "- You need to use the \"alpha\" option to make the graphs semitransparent\n",
    "- You will need to add a legend, label the axes, and the title\n",
    "- Note: The goal of this question is to illustrate that random <br>\n",
    "assignment produces very similar distributions between two groups\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your own code here\n",
    "data_urban = pd.read_csv(\"data/wdi_urban.csv\")\n",
    "\n",
    "list_years = pd.unique(data_urban[\"year\"])\n",
    "for year in list_years:\n",
    "    df = data_urban.query(\"year == @year\")\n",
    "    plt.hist(x=df[\"prop_urbanpopulation\"], alpha = 0.5)\n",
    "\n",
    "plt.xlabel(\"Proportion of Urban Population\")\n",
    "plt.ylabel(\"Number of Countries\")\n",
    "plt.title(\"Proportion of Urban Population for Countries in 1980 vs 2020\")\n",
    "plt.legend(labels = list_years, title=\"Years\")\n",
    "plt.show()\n",
    "\n",
    "# From this graph we can compare the distribution of different proportions \n",
    "# of urban populations in countries across 40 years. Countries in 2020 shift\n",
    "# right, suggesting a higher urban population globally. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42b0d7c6159d34a85365a73cb02b6d09d2fe374ec037592e43ae0fc926acaa1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
